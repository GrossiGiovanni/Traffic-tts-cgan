{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/giovannigrossi/traffic-tts-cgan?scriptVersionId=264938062\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","execution_count":1,"id":"090d3f09","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2025-09-30T19:18:54.528237Z","iopub.status.busy":"2025-09-30T19:18:54.527963Z","iopub.status.idle":"2025-09-30T19:18:55.929718Z","shell.execute_reply":"2025-09-30T19:18:55.928839Z"},"papermill":{"duration":1.40925,"end_time":"2025-09-30T19:18:55.931084","exception":false,"start_time":"2025-09-30T19:18:54.521834","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["/kaggle/input/dataset/data/normalization_params.pkl\n","/kaggle/input/dataset/data/X_train.npy\n","/kaggle/input/dataset/data/S_train.npy\n"]}],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":2,"id":"150c52cf","metadata":{"execution":{"iopub.execute_input":"2025-09-30T19:18:55.940471Z","iopub.status.busy":"2025-09-30T19:18:55.940154Z","iopub.status.idle":"2025-09-30T19:19:04.008876Z","shell.execute_reply":"2025-09-30T19:19:04.007908Z"},"papermill":{"duration":8.07462,"end_time":"2025-09-30T19:19:04.010188","exception":false,"start_time":"2025-09-30T19:18:55.935568","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Torch: 2.6.0+cu124\n"]}],"source":["!pip -q install einops torchsummary\n","import os, torch, numpy as np\n","print(\"Torch:\", torch.__version__)"]},{"cell_type":"code","execution_count":null,"id":"fda8452b","metadata":{"papermill":{"duration":0.00398,"end_time":"2025-09-30T19:19:04.018442","exception":false,"start_time":"2025-09-30T19:19:04.014462","status":"completed"},"tags":[]},"outputs":[],"source":[]},{"cell_type":"code","execution_count":3,"id":"24c9080f","metadata":{"execution":{"iopub.execute_input":"2025-09-30T19:19:04.027287Z","iopub.status.busy":"2025-09-30T19:19:04.026932Z","iopub.status.idle":"2025-09-30T19:19:04.154163Z","shell.execute_reply":"2025-09-30T19:19:04.153109Z"},"papermill":{"duration":0.133338,"end_time":"2025-09-30T19:19:04.155729","exception":false,"start_time":"2025-09-30T19:19:04.022391","status":"completed"},"tags":[]},"outputs":[],"source":["!mkdir -p /kaggle/working/traffic-tts-cgan"]},{"cell_type":"code","execution_count":4,"id":"01fc4482","metadata":{"execution":{"iopub.execute_input":"2025-09-30T19:19:04.165131Z","iopub.status.busy":"2025-09-30T19:19:04.164845Z","iopub.status.idle":"2025-09-30T19:19:04.17087Z","shell.execute_reply":"2025-09-30T19:19:04.170148Z"},"papermill":{"duration":0.011947,"end_time":"2025-09-30T19:19:04.171989","exception":false,"start_time":"2025-09-30T19:19:04.160042","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Writing /kaggle/working/traffic-tts-cgan/setup_dirs.py\n"]}],"source":["%%writefile /kaggle/working/traffic-tts-cgan/setup_dirs.py\n","\n","import os\n","BASE = \"/kaggle/working/traffic-tts-cgan\"\n","for p in [\n","BASE,\n","f\"{BASE}/src\",\n","f\"{BASE}/outputs\",\n","f\"{BASE}/outputs/checkpoints\",\n","f\"{BASE}/outputs/samples\",\n","f\"{BASE}/outputs/logs\",\n","f\"{BASE}/data_norm\",\n","]:\n","os.makedirs(p, exist_ok=True)\n","print(\"Project folders ready under\", BASE)\n"]},{"cell_type":"code","execution_count":5,"id":"6e1ae36f","metadata":{"execution":{"iopub.execute_input":"2025-09-30T19:19:04.180596Z","iopub.status.busy":"2025-09-30T19:19:04.180388Z","iopub.status.idle":"2025-09-30T19:19:04.184829Z","shell.execute_reply":"2025-09-30T19:19:04.18423Z"},"papermill":{"duration":0.009928,"end_time":"2025-09-30T19:19:04.185933","exception":false,"start_time":"2025-09-30T19:19:04.176005","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Cartella src creata: /kaggle/working/traffic-tts-cgan/src\n"]}],"source":["import os\n","\n","BASE = \"/kaggle/working/traffic-tts-cgan\"\n","SRC = f\"{BASE}/src\"\n","\n","os.makedirs(SRC, exist_ok=True)\n","print(\"Cartella src creata:\", SRC)"]},{"cell_type":"code","execution_count":6,"id":"5fa53eae","metadata":{"execution":{"iopub.execute_input":"2025-09-30T19:19:04.194397Z","iopub.status.busy":"2025-09-30T19:19:04.194216Z","iopub.status.idle":"2025-09-30T19:19:04.250377Z","shell.execute_reply":"2025-09-30T19:19:04.249712Z"},"papermill":{"duration":0.061684,"end_time":"2025-09-30T19:19:04.2515","exception":false,"start_time":"2025-09-30T19:19:04.189816","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["X shape: (178392, 120, 5) dtype: float64\n","S shape: (178392, 4) dtype: float64\n"]}],"source":["# Sostituisci con il path che hai trovato sopra\n","INPUT_DIR = \"/kaggle/input/dataset/data\"  \n","\n","import numpy as np\n","\n","X = np.load(f\"{INPUT_DIR}/X_train.npy\", mmap_mode=\"r\")\n","S = np.load(f\"{INPUT_DIR}/S_train.npy\", mmap_mode=\"r\")\n","\n","print(\"X shape:\", X.shape, \"dtype:\", X.dtype)\n","print(\"S shape:\", S.shape, \"dtype:\", S.dtype)\n","\n","# Se sono gi√† normalizzati, ignora pure i normalization params\n","# Se ti servisse caricarli (estensione .pki), probabilmente √® un pickle:\n","# import pickle\n","# with open(f\"{INPUT_DIR}/normalization params.pki\", \"rb\") as f:\n","#     norm_params = pickle.load(f)\n"]},{"cell_type":"code","execution_count":7,"id":"8624087f","metadata":{"execution":{"iopub.execute_input":"2025-09-30T19:19:04.261296Z","iopub.status.busy":"2025-09-30T19:19:04.26109Z","iopub.status.idle":"2025-09-30T19:19:14.925634Z","shell.execute_reply":"2025-09-30T19:19:14.924846Z"},"papermill":{"duration":10.671465,"end_time":"2025-09-30T19:19:14.927114","exception":false,"start_time":"2025-09-30T19:19:04.255649","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["RAW -> X: (178392, 120, 5) float64 range: -8.082757512467364 7.6915056926688585\n","RAW -> S: (178392, 4) float64 range: -1.5243292377218545 10.056652322841456\n","\n","POST-NORM:\n"," Xn: (178392, 120, 5) float32 range: -1.0 1.0\n"," Sn: (178392, 4) float32 range: -1.0 1.0\n","\n","Salvati:\n"," - /kaggle/working/traffic-tts-cgan/data_norm/X_train_norm.npy\n"," - /kaggle/working/traffic-tts-cgan/data_norm/S_train_norm.npy\n"]}],"source":["import os, numpy as np\n","\n","# === CONFIG ===\n","DATA_DIR = \"/kaggle/input/dataset/data\"   # <-- path al tuo dataset\n","OUT_DIR  = \"/kaggle/working/traffic-tts-cgan/data_norm\"\n","os.makedirs(OUT_DIR, exist_ok=True)\n","\n","# === 1) Carica dati ===\n","X = np.load(f\"{DATA_DIR}/X_train.npy\")   # (N, T, C)\n","S = np.load(f\"{DATA_DIR}/S_train.npy\")   # (N, F)\n","print(\"RAW -> X:\", X.shape, X.dtype, \"range:\", float(X.min()), float(X.max()))\n","print(\"RAW -> S:\", S.shape, S.dtype, \"range:\", float(S.min()), float(S.max()))\n","\n","# === 2) Ricalcola nuovi parametri (Min-Max per ogni feature) ===\n","# dinamiche\n","Xf = X.reshape(-1, X.shape[-1]).astype(np.float32)\n","X_min, X_max = Xf.min(axis=0), Xf.max(axis=0)\n","\n","# statiche numeriche (prime 2 colonne)\n","S_num = S[:, :2].astype(np.float32)\n","S_min, S_max = S_num.min(axis=0), S_num.max(axis=0)\n","\n","# === 3) Normalizzazione tra -1 e 1 ===\n","# formula: X_norm = 2 * (X - min) / (max - min) - 1\n","Xn = 2 * (Xf - X_min) / (X_max - X_min) - 1\n","Xn = Xn.reshape(X.shape)\n","\n","Sn_num = 2 * (S_num - S_min) / (S_max - S_min) - 1\n","S_cat = S[:, 2:]  # OHE lasciate intatte\n","Sn = np.concatenate([Sn_num, S_cat], axis=1).astype(np.float32)\n","\n","print(\"\\nPOST-NORM:\")\n","print(\" Xn:\", Xn.shape, Xn.dtype, \"range:\", float(Xn.min()), float(Xn.max()))\n","print(\" Sn:\", Sn.shape, Sn.dtype, \"range:\", float(Sn.min()), float(Sn.max()))\n","\n","# === 4) Salva ===\n","np.save(f\"{OUT_DIR}/X_train_norm.npy\", Xn)\n","np.save(f\"{OUT_DIR}/S_train_norm.npy\", Sn)\n","print(\"\\nSalvati:\")\n","print(\" -\", f\"{OUT_DIR}/X_train_norm.npy\")\n","print(\" -\", f\"{OUT_DIR}/S_train_norm.npy\")\n"]},{"cell_type":"code","execution_count":8,"id":"aa59f534","metadata":{"execution":{"iopub.execute_input":"2025-09-30T19:19:14.936847Z","iopub.status.busy":"2025-09-30T19:19:14.936435Z","iopub.status.idle":"2025-09-30T19:19:15.067471Z","shell.execute_reply":"2025-09-30T19:19:15.066462Z"},"papermill":{"duration":0.137223,"end_time":"2025-09-30T19:19:15.068811","exception":false,"start_time":"2025-09-30T19:19:14.931588","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["data\r\n"]}],"source":["!ls /kaggle/input/dataset"]},{"cell_type":"code","execution_count":9,"id":"f85cdd61","metadata":{"execution":{"iopub.execute_input":"2025-09-30T19:19:15.079619Z","iopub.status.busy":"2025-09-30T19:19:15.079101Z","iopub.status.idle":"2025-09-30T19:19:15.385901Z","shell.execute_reply":"2025-09-30T19:19:15.385053Z"},"papermill":{"duration":0.313417,"end_time":"2025-09-30T19:19:15.387219","exception":false,"start_time":"2025-09-30T19:19:15.073802","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["‚úì Caricamento OK\n","X: (178392, 120, 5) float32 min: -1.0 max: 1.0\n","S: (178392, 4) float32 min: -1.0 max: 1.0\n"]}],"source":["import numpy as np\n","\n","DATA_DIR = \"/kaggle/working/traffic-tts-cgan/data_norm\"  # oppure INPUT_DIR\n","\n","X = np.load(f\"{DATA_DIR}/X_train_norm.npy\", mmap_mode=None)  # None se vuoi tutto in RAM\n","S = np.load(f\"{DATA_DIR}/S_train_norm.npy\", mmap_mode=None)\n","\n","print(\"‚úì Caricamento OK\")\n","print(\"X:\", X.shape, X.dtype, \"min:\", X.min(), \"max:\", X.max())\n","print(\"S:\", S.shape, S.dtype, \"min:\", S.min(), \"max:\", S.max())\n"]},{"cell_type":"code","execution_count":10,"id":"f0eb0957","metadata":{"execution":{"iopub.execute_input":"2025-09-30T19:19:15.397193Z","iopub.status.busy":"2025-09-30T19:19:15.396586Z","iopub.status.idle":"2025-09-30T19:19:15.729174Z","shell.execute_reply":"2025-09-30T19:19:15.728425Z"},"papermill":{"duration":0.33865,"end_time":"2025-09-30T19:19:15.730341","exception":false,"start_time":"2025-09-30T19:19:15.391691","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["X_train: (178392, 120, 5) range -1.0 1.0\n","S_train: (178392, 4) range -1.0 1.0\n"]}],"source":["import numpy as np\n","\n","BASE = \"/kaggle/working/traffic-tts-cgan\"\n","\n","X_train = np.load(f\"{BASE}/data_norm/X_train_norm.npy\")\n","S_train = np.load(f\"{BASE}/data_norm/S_train_norm.npy\")\n","\n","print(\"X_train:\", X_train.shape, \"range\", X_train.min(), X_train.max())\n","print(\"S_train:\", S_train.shape, \"range\", S_train.min(), S_train.max())\n"]},{"cell_type":"code","execution_count":11,"id":"71f8cb2f","metadata":{"execution":{"iopub.execute_input":"2025-09-30T19:19:15.740558Z","iopub.status.busy":"2025-09-30T19:19:15.740022Z","iopub.status.idle":"2025-09-30T19:19:15.744915Z","shell.execute_reply":"2025-09-30T19:19:15.74429Z"},"papermill":{"duration":0.011024,"end_time":"2025-09-30T19:19:15.745988","exception":false,"start_time":"2025-09-30T19:19:15.734964","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Writing /kaggle/working/traffic-tts-cgan/src/dataset.py\n"]}],"source":["%%writefile /kaggle/working/traffic-tts-cgan/src/dataset.py\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","\n","\n","class TrafficDataset(Dataset):\n","    def __init__(self, X, S):\n","        assert X.ndim == 3, \"X must be (N, L, C)\"\n","        assert S.ndim == 2, \"S must be (N, D)\"\n","        assert X.shape[0] == S.shape[0], \"X and S must have same N\"\n","        self.X = torch.from_numpy(X).float()\n","        self.S = torch.from_numpy(S).float()\n","\n","\n","    def __len__(self):\n","        return self.X.shape[0]\n","    \n","    \n","    def __getitem__(self, idx):\n","        return self.X[idx], self.S[idx]\n","\n","\n","\n","\n","def make_loader(X, S, batch_size=128, num_workers=2, pin_memory=True, shuffle=True):\n","    ds = TrafficDataset(X, S)\n","    return DataLoader(ds, batch_size=batch_size, shuffle=shuffle,\n","                        num_workers=num_workers, pin_memory=pin_memory, drop_last=True)"]},{"cell_type":"code","execution_count":12,"id":"72a4d741","metadata":{"execution":{"iopub.execute_input":"2025-09-30T19:19:15.755617Z","iopub.status.busy":"2025-09-30T19:19:15.755419Z","iopub.status.idle":"2025-09-30T19:19:15.764051Z","shell.execute_reply":"2025-09-30T19:19:15.763488Z"},"papermill":{"duration":0.014731,"end_time":"2025-09-30T19:19:15.765088","exception":false,"start_time":"2025-09-30T19:19:15.750357","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Writing /kaggle/working/traffic-tts-cgan/src/models.py\n"]}],"source":["%%writefile /kaggle/working/traffic-tts-cgan/src/models.py\n","import math\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","# =========================================================================================\n","#  Modello: Conditional GAN per sequenze temporali multivariate basata su Transformer\n","#  - Generator (G): produce direttamente l'intera sequenza [B, L, C] in un solo passaggio,\n","#    (B batch size, L lunghezza seq, C nfeatures) guidato da rumore latente z e condizione s. \n","\n","#  - Discriminator (D): Projection Discriminator con spectral normalization. Riassume la\n","#    sequenza tramte un token CLS, poi combina uno score \"non condizionale\" con un termine\n","#    di proiezione che misura la coerenza con la condizione (s).\n","#\n","#  NOTE PRATICHE:\n","#  - L'output del G usa tanh\n","#  - seq_len di G e D deve coincidere; anche cond_dim deve essere identico su G e D.\n","#  - time_tokens sono parametri appresi che fungono da base \"posizionale\" per ogni timestep;\n","#    il positional encoding sinusoidale aggiunge una componente deterministica di posizione.\n","# =========================================================================================\n","\n","\n","# ---------- Positional Encoding (sinusoidale) ----------\n","class SinusoidalPositionalEncoding(nn.Module):\n","    \"\"\"\n","    Encoding posizionale sinusoidale in stile Transformer.\n","    Non ha parametri allenabili: dipende solo da (max_len, d_model)\n","    \n","    Args:\n","        d_model: dimensione dei token (embedding dim).\n","        max_len: lunghezza massima supportata (deve essere >= seq_len effettiva).\n","\n","    Forward:\n","        x: Tensor [B, L, d] usato solo per leggere L; il contenuto non viene usato.\n","        return: Tensor [1, L, d] pronto per essere broadcast-ato su B.\n","    \"\"\"\n","    def __init__(self, d_model: int, max_len: int):\n","        super().__init__()\n","        pe = torch.zeros(max_len, d_model)\n","        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)  # [L, 1]\n","        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n","        pe[:, 0::2] = torch.sin(position * div_term)  # dimensioni pari\n","        pe[:, 1::2] = torch.cos(position * div_term)  # dimensioni dispari\n","        self.register_buffer('pe', pe.unsqueeze(0))  # [1, L, d] (no grad)\n","\n","    def forward(self, x):  # x: [B, L, d]\n","        return self.pe[:, :x.size(1), :]\n","\n","\n","# ---------- Conditional LayerNorm (FiLM) ----------\n","class ConditionalLayerNorm(nn.Module):\n","    \"\"\"\n","    LayerNorm condizionale (stile FiLM): applica LN e poi modula (affine) tramite gamma/beta\n","    calcolati da un vettore di condizione c (es. concatenazione [z, s]).\n","\n","    Args:\n","        normalized_shape: dimensione del canale/embedding (d_model).\n","        cond_dim: dimensione del vettore di condizione c.\n","        eps: termine di stabilizzazione numerica per LayerNorm.\n","\n","    Forward:\n","        x: Tensor [B, L, d]\n","        c: Tensor [B, cond_dim]\n","        return: Tensor [B, L, d] modulato da c\n","    \"\"\"\n","    def __init__(self, normalized_shape: int, cond_dim: int, eps: float = 1e-5):\n","        super().__init__()\n","        self.ln = nn.LayerNorm(normalized_shape, elementwise_affine=False, eps=eps)  # affine via FiLM\n","        self.gamma = nn.Linear(cond_dim, normalized_shape)\n","        self.beta = nn.Linear(cond_dim, normalized_shape)\n","\n","    def forward(self, x, c):  # x: [B,L,d], c: [B,cond]\n","        y = self.ln(x)\n","        g = self.gamma(c).unsqueeze(1)  # [B,1,d]\n","        b = self.beta(c).unsqueeze(1)   # [B,1,d]\n","        return y * (1 + g) + b          # shift+scale dipendenti da c\n","\n","\n","# ---------- Transformer Blocks ----------\n","class CondTransformerBlock(nn.Module):\n","    \"\"\"\n","    Blocco Transformer pre-norm con modulazione condizionale:\n","    - LN condizionale (FiLM) prima dell'attenzione\n","    - self-attention multi-testa (batch_first=True ‚Üí input [B,L,d])\n","    - LN condizionale + feed-forward (GELU) con dropout\n","    - residual connections su entrambe le sottostrutture\n","\n","    Args:\n","        d_model, nhead, dim_ff, cond_dim, dropout: iperparametri standard Transformer.\n","    \"\"\"\n","    def __init__(self, d_model, nhead, dim_ff, cond_dim, dropout=0.1):\n","        super().__init__()\n","        self.ln1 = ConditionalLayerNorm(d_model, cond_dim)\n","        self.attn = nn.MultiheadAttention(d_model, nhead, dropout=dropout, batch_first=True)\n","        self.ln2 = ConditionalLayerNorm(d_model, cond_dim)\n","        self.ff = nn.Sequential(\n","            nn.Linear(d_model, dim_ff), nn.GELU(), nn.Dropout(dropout),\n","            nn.Linear(dim_ff, d_model), nn.Dropout(dropout)\n","        )\n","\n","    def forward(self, x, c):\n","        # Attenzione condizionata: la normalizzazione √® modulata da c\n","        h = self.ln1(x, c)\n","        attn_out, _ = self.attn(h, h, h, need_weights=False)  # self-attention bidirezionale\n","        x = x + attn_out\n","        # Feed-forward condizionato\n","        h2 = self.ln2(x, c)\n","        x = x + self.ff(h2)\n","        return x\n","\n","\n","class TransformerBlock(nn.Module):\n","    \"\"\"\n","    Blocco Transformer standard (pre-norm) usato nel Discriminatore.\n","    \"\"\"\n","    def __init__(self, d_model, nhead, dim_ff, dropout=0.1):\n","        super().__init__()\n","        self.ln1 = nn.LayerNorm(d_model)\n","        self.attn = nn.MultiheadAttention(d_model, nhead, dropout=dropout, batch_first=True)\n","        self.ln2 = nn.LayerNorm(d_model)\n","        self.ff = nn.Sequential(\n","            nn.Linear(d_model, dim_ff), nn.GELU(), nn.Dropout(dropout),\n","            nn.Linear(dim_ff, d_model), nn.Dropout(dropout)\n","        )\n","\n","    def forward(self, x):\n","        h = self.ln1(x)\n","        attn_out, _ = self.attn(h, h, h, need_weights=False)\n","        x = x + attn_out\n","        h2 = self.ln2(x)\n","        x = x + self.ff(h2)\n","        return x\n","\n","\n","class Generator(nn.Module):\n","    \"\"\"\n","    Generatore: produce sequenze multivariate coerenti con la condizione s.\n","\n","    Idea chiave:\n","    - Si costruisce una \"tela temporale\" di lunghezza L con token appresi (time_tokens) + PE sinusoidale.\n","    - Si inietta un bias globale g (proiezione di z ed s) su tutti i timestep.\n","    - Si attraversa una pila di CondTransformerBlock modulati dalla condizione c=[z,s].\n","    - Proiezione finale in C canali e tanh ‚Üí [-1, 1].\n","\n","    Args:\n","        seq_len: L, lunghezza della sequenza temporale generata.\n","        channels: C, numero di feature per timestep.\n","        cond_dim: dim(s), dimensione del vettore condizionale esterno.\n","        latent_dim: dim(z), dimensione del rumore latente.\n","        d_model, depth, nhead, dim_ff, dropout: iperparametri dei Transformer.\n","\n","    Forward:\n","        z: [B, latent_dim]  (variabilit√†)\n","        s: [B, cond_dim]    (condizione esterna)\n","        return: [B, L, C] in [-1,1]\n","    \"\"\"\n","    def __init__(self,\n","                 seq_len=120,\n","                 channels=5,\n","                 cond_dim=4,\n","                 latent_dim=128,\n","                 d_model=256,\n","                 depth=6,\n","                 nhead=8,\n","                 dim_ff=512,\n","                 dropout=0.1):\n","        super().__init__()\n","        self.seq_len = seq_len\n","        self.channels = channels\n","        self.latent_dim = latent_dim\n","        self.cond_dim = cond_dim\n","        self.total_cond = latent_dim + cond_dim\n","\n","        # Base temporale: token appresi per ogni posizione + pe sinusoidale deterministica\n","        self.time_tokens = nn.Parameter(torch.randn(seq_len, d_model))          # [L,d]\n","        self.pos_enc = SinusoidalPositionalEncoding(d_model, seq_len)           # [1,L,d]\n","\n","        # Proiezioni per creare:\n","        # - un bias globale g da sommare a tutti i timestep\n","        # - un vettore di condizione c = [z,s] per FiLM nei blocchi\n","        self.noise_proj = nn.Linear(latent_dim, d_model)\n","        self.cond_proj = nn.Linear(cond_dim, d_model)\n","\n","        self.blocks = nn.ModuleList([\n","            CondTransformerBlock(d_model, nhead, dim_ff, self.total_cond, dropout)\n","            for _ in range(depth)\n","        ])\n","        self.to_data = nn.Linear(d_model, channels)\n","\n","    def forward(self, z, s):  # z:[B,latent], s:[B,cond]\n","        B = z.size(0)\n","        c = torch.cat([z, s], dim=1)  # [B, total_cond] ‚Üí condizione per FiLM nei blocchi\n","\n","        # Tela temporale: [B, L, d] = (token appresi + PE) replicati per il batch\n","        base = self.time_tokens.unsqueeze(0).expand(B, -1, -1)  # [B, L, d]\n","        pos = self.pos_enc(base)                                # [1, L, d]\n","        h = base + pos                                          # [B, L, d]\n","\n","        # Iniezione globale di z e s come bias condiviso su tutti i timestep\n","        g = self.noise_proj(z) + self.cond_proj(s)  # [B,d]\n","        h = h + g.unsqueeze(1)                      # broadcast su L\n","\n","        # Trasformazioni condizionate lungo la profondit√†\n","        for blk in self.blocks:\n","            h = blk(h, c)\n","\n","        # Proiezione nei C canali e squash in [-1,1]\n","        x = self.to_data(h)               # [B, L, C]\n","        return torch.tanh(x)              # normalizzazione coerente coi target\n","\n","\n","# ---------- Discriminator (Projection) ----------\n","class Discriminator(nn.Module):\n","    \"\"\"\n","    Discriminatore con Projection Head (Miyato & Koyama, 2018):\n","    - Proietta la sequenza nei token d_model.\n","    - Preprende un token CLS appreso che \"riassume\" la sequenza.\n","    - Aggiunge positional encoding sinusoidale (sul CLS e sui token dati).\n","    - Passa attraverso blocchi Transformer standard.\n","    - Dal token CLS finale calcola:\n","        * uno score scalare via Linear (SN)\n","        * un termine di proiezione: <W_c s, h_cls> che valuta coerenza con la condizione.\n","      Lo score finale √® la somma dei due.\n","\n","    Args:\n","        seq_len, channels, cond_dim, d_model, depth, nhead, dim_ff, dropout: come da G.\n","\n","    Forward:\n","        x: [B, L, C] (reale o generato)\n","        s: [B, cond_dim]\n","        return: [B] (score per sequenza)\n","    \"\"\"\n","    def __init__(self,\n","                 seq_len=120,\n","                 channels=5,\n","                 cond_dim=4,\n","                 d_model=256,\n","                 depth=6,\n","                 nhead=8,\n","                 dim_ff=512,\n","                 dropout=0.1):\n","        super().__init__()\n","        sn = nn.utils.spectral_norm\n","        self.seq_len = seq_len\n","\n","        # Ingresso: per-timestep C ‚Üí d_model (SN per stabilit√†)\n","        self.from_data = sn(nn.Linear(channels, d_model))\n","        # Token CLS appreso per riassumere l'intera sequenza\n","        self.cls_token = nn.Parameter(torch.randn(1, 1, d_model))\n","        # PE su (1 + L) posizioni (CLS + L timestep)\n","        self.pos_enc = SinusoidalPositionalEncoding(d_model, seq_len + 1)\n","\n","        self.blocks = nn.ModuleList([\n","            TransformerBlock(d_model, nhead, dim_ff, dropout)\n","            for _ in range(depth)\n","        ])\n","        self.ln = nn.LayerNorm(d_model)\n","        self.out = sn(nn.Linear(d_model, 1))         # score \"non condizionale\"\n","        self.cond_proj = sn(nn.Linear(cond_dim, d_model))  # embedding condizione per proiezione\n","\n","    def forward(self, x, s):  # x:[B,L,C], s:[B,cond]\n","        B = x.size(0)\n","        h = self.from_data(x)                     # [B,L,d]\n","        cls = self.cls_token.expand(B, -1, -1)    # [B,1,d]\n","        h = torch.cat([cls, h], dim=1)            # [B, 1+L, d]\n","        h = h + self.pos_enc(h)                   # PE su CLS e token\n","\n","        # Modellazione contestuale lungo la sequenza\n","        for blk in self.blocks:\n","            h = blk(h)\n","\n","        # Riassunto dal token CLS (posizione 0)\n","        h_cls = self.ln(h[:, 0, :])               # [B,d]\n","\n","        # Score base + termine di proiezione condizionale\n","        score = self.out(h_cls)                   # [B,1]\n","        proj = torch.sum(self.cond_proj(s) * h_cls, dim=1, keepdim=True)  # [B,1]\n","        return (score + proj).squeeze(1)          # [B]\n","\n","\n","def build_models(seq_len=120, channels=5, cond_dim=4,\n","                 latent_dim=128, d_model=256, depth=6, nhead=8, dim_ff=512, dropout=0.1):\n","    \"\"\"\n","    Costruisce coppia (Generator, Discriminator) con iperparametri condivisi.\n","\n","    Returns:\n","        G: Generator\n","        D: Discriminator\n","\n","    Esempio d'uso:\n","        G, D = build_models(seq_len=120, channels=5, cond_dim=4)\n","        z = torch.randn(B, 128)\n","        s = torch.randn(B, 4)\n","        x_fake = G(z, s)           # [B,120,5] in [-1,1]\n","        score = D(x_fake, s)       # [B]\n","    \"\"\"\n","    G = Generator(seq_len, channels, cond_dim, latent_dim, d_model, depth, nhead, dim_ff, dropout)\n","    D = Discriminator(seq_len, channels, cond_dim, d_model, depth, nhead, dim_ff, dropout)\n","    return G, D\n"]},{"cell_type":"code","execution_count":13,"id":"11bef15d","metadata":{"execution":{"iopub.execute_input":"2025-09-30T19:19:15.774953Z","iopub.status.busy":"2025-09-30T19:19:15.774235Z","iopub.status.idle":"2025-09-30T19:19:15.778507Z","shell.execute_reply":"2025-09-30T19:19:15.77794Z"},"papermill":{"duration":0.01002,"end_time":"2025-09-30T19:19:15.779503","exception":false,"start_time":"2025-09-30T19:19:15.769483","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Writing /kaggle/working/traffic-tts-cgan/src/losses.py\n"]}],"source":["%%writefile /kaggle/working/traffic-tts-cgan/src/losses.py\n","import torch\n","import torch.nn.functional as F\n","\n","\n","def d_hinge_loss(real_scores, fake_scores):\n","    loss_real = torch.relu(1.0 - real_scores).mean()\n","    loss_fake = torch.relu(1.0 + fake_scores).mean()\n","    return loss_real + loss_fake\n","\n","\n","\n","\n","def g_hinge_loss(fake_scores):\n","    return (-fake_scores).mean()\n","\n","\n","\n","\n","def r1_regularizer(real_scores, real_x, gamma=1.0):\n","    # real_x: [B,L,C]\n","    grads = torch.autograd.grad(outputs=real_scores.sum(), inputs=real_x,\n","    create_graph=True, retain_graph=True, only_inputs=True)[0]\n","    penalty = grads.reshape(grads.size(0), -1).pow(2).sum(dim=1).mean()\n","    return 0.5 * gamma * penalty"]},{"cell_type":"code","execution_count":14,"id":"2cc601d2","metadata":{"execution":{"iopub.execute_input":"2025-09-30T19:19:15.789432Z","iopub.status.busy":"2025-09-30T19:19:15.789242Z","iopub.status.idle":"2025-09-30T19:19:15.794605Z","shell.execute_reply":"2025-09-30T19:19:15.794084Z"},"papermill":{"duration":0.011788,"end_time":"2025-09-30T19:19:15.795611","exception":false,"start_time":"2025-09-30T19:19:15.783823","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Writing /kaggle/working/traffic-tts-cgan/src/utils.py\n"]}],"source":["%%writefile /kaggle/working/traffic-tts-cgan/src/utils.py\n","import os, math, json, time, random\n","import numpy as np\n","import torch\n","from matplotlib import pyplot as plt\n","\n","\n","\n","\n","def set_seed(seed=42):\n","    random.seed(seed); np.random.seed(seed); torch.manual_seed(seed); torch.cuda.manual_seed_all(seed)\n","    \n","\n","\n","\n","def save_checkpoint(path, G, D, g_opt, d_opt, epoch, cfg):\n","    os.makedirs(os.path.dirname(path), exist_ok=True)\n","    torch.save({\n","        'epoch': epoch,\n","        'G': G.state_dict(),\n","        'D': D.state_dict(),\n","        'g_opt': g_opt.state_dict(),\n","        'd_opt': d_opt.state_dict(),\n","        'cfg': cfg,\n","    }, path)\n","\n","\n","\n","\n","def load_checkpoint(path, G, D, g_opt=None, d_opt=None, map_location='cpu'):\n","    ckpt = torch.load(path, map_location=map_location)\n","    G.load_state_dict(ckpt['G'])\n","    D.load_state_dict(ckpt['D'])\n","    if g_opt is not None and d_opt is not None:\n","        g_opt.load_state_dict(ckpt['g_opt'])\n","        d_opt.load_state_dict(ckpt['d_opt'])\n","    return ckpt.get('epoch', 0), ckpt.get('cfg', {})\n","\n","\n","\n","\n","def generate(G, S, n_samples=None, latent_dim=128, device='cuda'):\n","    G.eval()\n","    with torch.no_grad():\n","        S = torch.as_tensor(S, dtype=torch.float32, device=device)\n","        if n_samples is None:\n","            n_samples = S.size(0)\n","        z = torch.randn(n_samples, latent_dim, device=device)\n","        X_hat = G(z, S[:n_samples]) # [N,L,C]\n","        return X_hat.detach().cpu().numpy()\n","\n","\n","\n","\n","def quick_plot_pairs(real, fake, num_series=3, title_prefix=\"\"):\n","    L = real.shape[0]\n","    t = np.arange(L)\n","    cols = min(num_series, real.shape[1])\n","    plt.figure(figsize=(12, 3*cols))\n","    for c in range(cols):\n","        plt.subplot(cols, 1, c+1)\n","        plt.plot(t, real[:, c], label='real')\n","        plt.plot(t, fake[:, c], label='fake', alpha=0.8)\n","        plt.xlabel('t'); plt.ylabel(f'ch{c}')\n","        plt.legend()\n","    plt.suptitle(f\"{title_prefix} ‚Äî overlay real vs fake\")\n","    plt.tight_layout(); plt.show()\n","\n","\n","\n","def evaluate_metrics(G, X_real, S_real, n_samples=100, latent_dim=128, device=\"cuda\"):\n","    \"\"\"\n","    Calcola metriche di base per confrontare i dati reali con quelli generati dal Generatore.\n","\n","    Parametri:\n","    - G: modello Generator (gi√† addestrato, in eval mode)\n","    - X_real: array numpy con sequenze reali (N, T, C)\n","    - S_real: array numpy con feature statiche (N, F)\n","    - n_samples: quanti campioni usare per la valutazione (default=200)\n","    - latent_dim: dimensione del rumore latente\n","    - device: 'cuda' o 'cpu'\n","\n","    Ritorna:\n","    - dizionario con MMD e statistiche base (media/std reali vs fake)\n","    \"\"\"\n","    import numpy as np, torch\n","    G.eval()\n","\n","    # 1) Scegliamo un sottoinsieme casuale di dati reali\n","    n_total = len(X_real)\n","    idx = np.random.choice(n_total, size=min(n_samples, n_total), replace=False)\n","\n","    # 2) Convertiamo i dati scelti in tensori PyTorch sul device giusto\n","    Xr = torch.tensor(X_real[idx], dtype=torch.float32, device=device)  # sequenze reali\n","    Sr = torch.tensor(S_real[idx], dtype=torch.float32, device=device)  # feature statiche reali\n","\n","    # 3) Generiamo sequenze finte con il generatore, usando lo stesso subset di condizioni\n","    with torch.no_grad():\n","        z = torch.randn(len(idx), latent_dim, device=device)  # rumore latente\n","        Xg = G(z, Sr).detach().cpu().numpy()                 # sequenze generate\n","\n","    # 4) Flatten per confronto statistico (collassa tempo e batch in un'unica dimensione)\n","    real_flat = Xr.cpu().numpy().reshape(-1, Xr.shape[-1])   # (N*T, C)\n","    fake_flat = Xg.reshape(-1, Xg.shape[-1])                 # (N*T, C)\n","\n","    # 5) Calcolo MMD (distanza tra distribuzioni reali e generate)\n","    mmd_val = rbf_mmd(torch.tensor(real_flat), torch.tensor(fake_flat))\n","\n","    # 6) Statistiche base: media e deviazione standard per ogni canale\n","    stats = {}\n","    for c in range(real_flat.shape[1]):\n","        stats[f\"ch{c}_mean_real\"] = float(real_flat[:, c].mean())\n","        stats[f\"ch{c}_mean_fake\"] = float(fake_flat[:, c].mean())\n","        stats[f\"ch{c}_std_real\"]  = float(real_flat[:, c].std())\n","        stats[f\"ch{c}_std_fake\"]  = float(fake_flat[:, c].std())\n","\n","    # 7) Ritorniamo tutte le metriche in un dizionario\n","    return {\"mmd\": mmd_val, **stats}\n","\n","\n","\n","def rbf_mmd(x, y, sigma=1.0):\n","    # x: [N,D], y: [M,D]\n","    import torch\n","    def pdist(a, b):\n","        a2 = (a*a).sum(1, keepdim=True)\n","        b2 = (b*b).sum(1, keepdim=True)\n","        return a2 + b2.T - 2*a@b.T\n","    Kxx = torch.exp(-pdist(x, x)/(2*sigma**2))\n","    Kyy = torch.exp(-pdist(y, y)/(2*sigma**2))\n","    Kxy = torch.exp(-pdist(x, y)/(2*sigma**2))\n","    mmd = Kxx.mean() + Kyy.mean() - 2*Kxy.mean()\n","    return mmd.item()"]},{"cell_type":"code","execution_count":15,"id":"7e211f7b","metadata":{"execution":{"iopub.execute_input":"2025-09-30T19:19:15.805496Z","iopub.status.busy":"2025-09-30T19:19:15.805306Z","iopub.status.idle":"2025-09-30T19:19:15.811049Z","shell.execute_reply":"2025-09-30T19:19:15.810384Z"},"papermill":{"duration":0.012038,"end_time":"2025-09-30T19:19:15.812104","exception":false,"start_time":"2025-09-30T19:19:15.800066","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Writing /kaggle/working/traffic-tts-cgan/src/train.py\n"]}],"source":["%%writefile /kaggle/working/traffic-tts-cgan/src/train.py\n","# ===== train.py (light version) =====\n","import os, time, gc\n","import numpy as np\n","\n","import torch\n","from torch import optim\n","from torch.cuda import amp\n","\n","from dataset import make_loader\n","from models import build_models\n","from losses import d_hinge_loss, g_hinge_loss\n","from utils import set_seed, save_checkpoint\n","\n","\n","def train_gan(\n","    X_train, S_train,\n","    proj_dir=\"/kaggle/working/traffic-tts-cgan\",\n","    batch_size=128, epochs=5, lr=1e-4,\n","    latent_dim=128, d_model=128, depth=3, nhead=None, ff_dim=None, dropout=0.1,\n","    workers=2, use_amp=False, r1_every=8, r1_gamma=1.0, seed=42\n","):\n","    \"\"\"\n","    Training loop per la cGAN su time-series di traffico.\n","    Assunzioni: X_train in [-1,1], shape (N, T, C); S_train shape (N, F).\n","    \"\"\"\n","\n","    set_seed(seed)\n","    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","    # üîß Evita backend SDPA 'efficient'/'flash' che pu√≤ rompere il backward\n","    if device == \"cuda\":\n","        try:\n","            torch.backends.cuda.sdp_kernel(enable_flash=False, enable_math=True, enable_mem_efficient=False)\n","            print(\"SDPA backends -> flash=False, math=True, mem_efficient=False\")\n","        except Exception as e:\n","            print(\"SDPA config skipped:\", e)\n","\n","    scaler = amp.GradScaler(enabled=(device == \"cuda\" and use_amp))\n","\n","    # ===== DataLoader =====\n","    loader = make_loader(\n","        X_train, S_train,\n","        batch_size=batch_size,\n","        num_workers=workers,\n","        pin_memory=(device == \"cuda\"),\n","        shuffle=True\n","    )\n","\n","    # ===== Modelli =====\n","    seq_len, channels = X_train.shape[1], X_train.shape[2]\n","    cond_dim = S_train.shape[1]\n","    G, D = build_models(seq_len, channels, cond_dim,\n","                        latent_dim, d_model, depth, nhead, ff_dim, dropout)\n","    G.to(device); D.to(device)\n","\n","    g_opt = optim.Adam(G.parameters(), lr=lr, betas=(0.5, 0.999))\n","    d_opt = optim.Adam(D.parameters(), lr=lr, betas=(0.5, 0.999))\n","\n","    ckpt_dir   = os.path.join(proj_dir, \"outputs\", \"checkpoints\")\n","    sample_dir = os.path.join(proj_dir, \"outputs\", \"samples\")\n","    os.makedirs(ckpt_dir, exist_ok=True)\n","    os.makedirs(sample_dir, exist_ok=True)\n","\n","    step = 0\n","    log_every = 50\n","\n","    for epoch in range(1, epochs + 1):\n","        G.train(); D.train()\n","        for xb, sb in loader:\n","            xb = xb.to(device, dtype=torch.float32, non_blocking=True)\n","            sb = sb.to(device, dtype=torch.float32, non_blocking=True)\n","            B  = xb.size(0)\n","\n","            # ====== Train D ======\n","            z = torch.randn(B, latent_dim, device=device)\n","            with amp.autocast(enabled=(device == \"cuda\" and use_amp)):\n","                x_fake = G(z, sb).detach()\n","                real_scores = D(xb, sb)\n","                fake_scores = D(x_fake, sb)\n","                d_loss = d_hinge_loss(real_scores, fake_scores)\n","\n","            d_opt.zero_grad(set_to_none=True)\n","            scaler.scale(d_loss).backward()\n","            scaler.step(d_opt)\n","\n","            # ====== Train G ======\n","            z = torch.randn(B, latent_dim, device=device)\n","            with amp.autocast(enabled=(device == \"cuda\" and use_amp)):\n","                x_fake = G(z, sb)\n","                fake_scores = D(x_fake, sb)\n","                g_loss = g_hinge_loss(fake_scores)\n","\n","            g_opt.zero_grad(set_to_none=True)\n","            scaler.scale(g_loss).backward()\n","            scaler.step(g_opt)\n","            scaler.update()\n","\n","            if step % log_every == 0:\n","                print(f\"[ep {epoch}/{epochs} | step {step}] \"\n","                      f\"d_loss={d_loss.item():.4f} | g_loss={g_loss.item():.4f}\")\n","            step += 1\n","\n","        # ===== Fine epoca =====\n","        if epoch % 2 == 0 or epoch == epochs:\n","            # Sample (CSV disattivati per alleggerire, puoi riattivare se serve)\n","            with torch.no_grad():\n","                z = torch.randn(4, latent_dim, device=device)\n","                s = torch.tensor(S_train[:4], device=device, dtype=torch.float32)\n","                _ = G(z, s).detach().cpu().numpy()\n","                # esempio: np.savetxt(...)\n","\n","            # Metriche leggere\n","            from utils import evaluate_metrics\n","            metrics = evaluate_metrics(G, X_train, S_train,\n","                                       n_samples=200,\n","                                       latent_dim=latent_dim,\n","                                       device=device)\n","            print(f\"[ep {epoch}] MMD={metrics['mmd']:.4f}\")\n","\n","            # Checkpoint\n","            cfg = dict(batch_size=batch_size, epochs=epochs, lr=lr, latent_dim=latent_dim,\n","                       d_model=d_model, depth=depth, dropout=dropout, use_amp=use_amp, seed=seed,\n","                       seq_len=seq_len, channels=channels, cond_dim=cond_dim)\n","            save_checkpoint(os.path.join(ckpt_dir, f\"ckpt_ep{epoch:03d}.pt\"),\n","                            G, D, g_opt, d_opt, epoch, cfg)\n","\n","        # Pulizia memoria per evitare OOM\n","        gc.collect()\n","        if device == \"cuda\":\n","            torch.cuda.empty_cache()\n","\n","    return G, D, cfg\n"]},{"cell_type":"code","execution_count":16,"id":"f7d4e22d","metadata":{"execution":{"iopub.execute_input":"2025-09-30T19:19:15.821828Z","iopub.status.busy":"2025-09-30T19:19:15.821602Z","iopub.status.idle":"2025-09-30T19:19:15.834002Z","shell.execute_reply":"2025-09-30T19:19:15.8334Z"},"papermill":{"duration":0.018393,"end_time":"2025-09-30T19:19:15.835054","exception":false,"start_time":"2025-09-30T19:19:15.816661","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Contenuto src: ['utils.py', 'dataset.py', 'losses.py', 'models.py', 'train.py']\n","‚úîÔ∏è Moduli importati correttamente\n"]}],"source":["import sys, os, importlib\n","\n","SRC_DIR = \"/kaggle/working/traffic-tts-cgan/src\"\n","\n","# 1) Aggiungo la cartella src al path una sola volta\n","if SRC_DIR not in sys.path:\n","    sys.path.insert(0, SRC_DIR)\n","\n","# 2) Verifico che ci siano i file\n","print(\"Contenuto src:\", os.listdir(SRC_DIR))\n","\n","# 3) Importo tutti i moduli principali\n","import models, train, dataset, losses, utils\n","\n","# 4) Se modifichi i file e vuoi ricaricarli senza riavviare il kernel\n","importlib.reload(models)\n","importlib.reload(train)\n","importlib.reload(dataset)\n","importlib.reload(losses)\n","importlib.reload(utils)\n","\n","print(\"‚úîÔ∏è Moduli importati correttamente\")\n"]},{"cell_type":"code","execution_count":17,"id":"8eb92d45","metadata":{"execution":{"iopub.execute_input":"2025-09-30T19:19:15.84473Z","iopub.status.busy":"2025-09-30T19:19:15.844505Z","iopub.status.idle":"2025-09-30T19:19:16.759046Z","shell.execute_reply":"2025-09-30T19:19:16.75823Z"},"papermill":{"duration":0.920582,"end_time":"2025-09-30T19:19:16.760142","exception":false,"start_time":"2025-09-30T19:19:15.83956","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["‚úîÔ∏è Forward di G e D OK\n"]}],"source":["import torch\n","import sys\n","from importlib import reload\n","\n","# Aggiungo la cartella src al sys.path, cos√¨ Python trova i moduli locali\n","sys.path.insert(0, \"/kaggle/working/traffic-tts-cgan/src\")\n","\n","# Importo il modulo models e lo ricarico (utile se l'hai appena modificato)\n","import models\n","reload(models)\n","\n","# Imposto il device\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","# Costruisco Generator e Discriminator con i parametri di default (seq_len=120, channels=5, cond_dim=4)\n","G, D = models.build_models()\n","G, D = G.to(device), D.to(device)\n","\n","# Dummy input per testare la forward\n","B, T, C, s_dim, zdim = 8, 120, 5, 4, 128\n","z = torch.randn(B, zdim, device=device)       # rumore latente\n","s = torch.randn(B, s_dim, device=device)      # condizione\n","x_fake = G(z, s)                              # generazione\n","\n","# Controllo che l'output abbia shape corretta e range [-1,1]\n","assert x_fake.shape == (B, T, C), f\"Shape errata: {x_fake.shape}\"\n","assert torch.all(x_fake <= 1.0) and torch.all(x_fake >= -1.0), \"Valori fuori range [-1,1]\"\n","\n","# Testo il discriminator\n","score = D(x_fake, s)\n","assert score.shape == (B,), f\"Shape errata: {score.shape}\"\n","\n","print(\"‚úîÔ∏è Forward di G e D OK\")\n"]},{"cell_type":"code","execution_count":18,"id":"d2942c33","metadata":{"execution":{"iopub.execute_input":"2025-09-30T19:19:16.770258Z","iopub.status.busy":"2025-09-30T19:19:16.770039Z","iopub.status.idle":"2025-09-30T19:19:16.775352Z","shell.execute_reply":"2025-09-30T19:19:16.77473Z"},"papermill":{"duration":0.011473,"end_time":"2025-09-30T19:19:16.776311","exception":false,"start_time":"2025-09-30T19:19:16.764838","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Contenuto src: ['utils.py', 'dataset.py', '__pycache__', 'losses.py', 'models.py', 'train.py']\n","‚úîÔ∏è Modulo train importato: <module 'train' from '/kaggle/working/traffic-tts-cgan/src/train.py'>\n"]}],"source":["import sys, importlib, os\n","\n","# 1) Aggiungo la cartella src al sys.path\n","SRC_DIR = \"/kaggle/working/traffic-tts-cgan/src\"\n","if SRC_DIR not in sys.path:\n","    sys.path.insert(0, SRC_DIR)\n","\n","# 2) Verifico che train.py esista davvero\n","print(\"Contenuto src:\", os.listdir(SRC_DIR))\n","\n","# 3) Importo e ricarico train\n","import train\n","importlib.reload(train)\n","\n","print(\"‚úîÔ∏è Modulo train importato:\", train)\n"]},{"cell_type":"code","execution_count":19,"id":"44cf6251","metadata":{"execution":{"iopub.execute_input":"2025-09-30T19:19:16.786427Z","iopub.status.busy":"2025-09-30T19:19:16.78579Z","iopub.status.idle":"2025-09-30T19:29:32.171956Z","shell.execute_reply":"2025-09-30T19:29:32.171056Z"},"papermill":{"duration":615.392579,"end_time":"2025-09-30T19:29:32.173408","exception":false,"start_time":"2025-09-30T19:19:16.780829","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["SDPA backends -> flash=False, math=True, mem_efficient=False\n"]},{"name":"stderr","output_type":"stream","text":["/usr/lib/python3.11/contextlib.py:105: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.\n","  self.gen = func(*args, **kwds)\n","/kaggle/working/traffic-tts-cgan/src/train.py:38: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n","  scaler = amp.GradScaler(enabled=(device == \"cuda\" and use_amp))\n","/kaggle/working/traffic-tts-cgan/src/train.py:76: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with amp.autocast(enabled=(device == \"cuda\" and use_amp)):\n","/kaggle/working/traffic-tts-cgan/src/train.py:88: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with amp.autocast(enabled=(device == \"cuda\" and use_amp)):\n"]},{"name":"stdout","output_type":"stream","text":["[ep 1/2 | step 0] d_loss=5.6933 | g_loss=-1.3941\n","[ep 1/2 | step 50] d_loss=3.1258 | g_loss=-0.1508\n","[ep 1/2 | step 100] d_loss=2.3616 | g_loss=-0.2783\n","[ep 1/2 | step 150] d_loss=1.2582 | g_loss=0.2666\n","[ep 1/2 | step 200] d_loss=1.3928 | g_loss=-0.3731\n","[ep 1/2 | step 250] d_loss=1.4471 | g_loss=0.5546\n","[ep 1/2 | step 300] d_loss=1.1102 | g_loss=2.7403\n","[ep 1/2 | step 350] d_loss=1.1732 | g_loss=1.3847\n","[ep 1/2 | step 400] d_loss=1.4170 | g_loss=0.6348\n","[ep 1/2 | step 450] d_loss=1.1553 | g_loss=2.3693\n","[ep 1/2 | step 500] d_loss=0.8645 | g_loss=1.6489\n","[ep 1/2 | step 550] d_loss=1.2614 | g_loss=1.4439\n","[ep 1/2 | step 600] d_loss=0.7477 | g_loss=1.8216\n","[ep 1/2 | step 650] d_loss=2.5145 | g_loss=-0.1606\n","[ep 1/2 | step 700] d_loss=1.9309 | g_loss=3.0462\n","[ep 1/2 | step 750] d_loss=0.9353 | g_loss=2.3711\n","[ep 1/2 | step 800] d_loss=1.0185 | g_loss=0.4180\n","[ep 1/2 | step 850] d_loss=0.9222 | g_loss=2.4069\n","[ep 1/2 | step 900] d_loss=1.0423 | g_loss=1.5258\n","[ep 1/2 | step 950] d_loss=0.8603 | g_loss=1.6812\n","[ep 1/2 | step 1000] d_loss=0.8303 | g_loss=1.9521\n","[ep 1/2 | step 1050] d_loss=0.6778 | g_loss=1.8092\n","[ep 1/2 | step 1100] d_loss=1.2619 | g_loss=0.9539\n","[ep 1/2 | step 1150] d_loss=1.5026 | g_loss=0.5090\n","[ep 1/2 | step 1200] d_loss=1.7883 | g_loss=0.5119\n","[ep 1/2 | step 1250] d_loss=1.0886 | g_loss=1.3371\n","[ep 1/2 | step 1300] d_loss=0.8554 | g_loss=1.7023\n","[ep 1/2 | step 1350] d_loss=0.8826 | g_loss=1.7536\n","[ep 1/2 | step 1400] d_loss=0.7947 | g_loss=0.7643\n","[ep 1/2 | step 1450] d_loss=0.8455 | g_loss=1.7365\n","[ep 1/2 | step 1500] d_loss=0.9868 | g_loss=0.7479\n","[ep 1/2 | step 1550] d_loss=1.2003 | g_loss=0.1001\n","[ep 1/2 | step 1600] d_loss=0.5116 | g_loss=2.0786\n","[ep 1/2 | step 1650] d_loss=0.4266 | g_loss=1.2374\n","[ep 1/2 | step 1700] d_loss=1.8474 | g_loss=1.0915\n","[ep 1/2 | step 1750] d_loss=0.5806 | g_loss=2.0150\n","[ep 1/2 | step 1800] d_loss=0.9667 | g_loss=1.1190\n","[ep 1/2 | step 1850] d_loss=0.5946 | g_loss=2.4608\n","[ep 1/2 | step 1900] d_loss=0.1866 | g_loss=2.5188\n","[ep 1/2 | step 1950] d_loss=0.1659 | g_loss=2.4568\n","[ep 1/2 | step 2000] d_loss=0.3946 | g_loss=3.1166\n","[ep 1/2 | step 2050] d_loss=0.3536 | g_loss=2.0842\n","[ep 1/2 | step 2100] d_loss=0.1990 | g_loss=2.6365\n","[ep 1/2 | step 2150] d_loss=0.3884 | g_loss=1.9440\n","[ep 1/2 | step 2200] d_loss=0.4209 | g_loss=2.4197\n","[ep 1/2 | step 2250] d_loss=0.4031 | g_loss=3.4015\n","[ep 1/2 | step 2300] d_loss=0.2486 | g_loss=1.6261\n","[ep 1/2 | step 2350] d_loss=0.2694 | g_loss=2.4311\n","[ep 1/2 | step 2400] d_loss=0.3637 | g_loss=2.5992\n","[ep 1/2 | step 2450] d_loss=0.6003 | g_loss=2.1772\n","[ep 1/2 | step 2500] d_loss=0.1540 | g_loss=2.2520\n","[ep 1/2 | step 2550] d_loss=0.1857 | g_loss=2.3346\n","[ep 1/2 | step 2600] d_loss=0.1841 | g_loss=2.7217\n","[ep 1/2 | step 2650] d_loss=0.1966 | g_loss=3.0374\n","[ep 1/2 | step 2700] d_loss=0.2196 | g_loss=1.9084\n","[ep 1/2 | step 2750] d_loss=0.3533 | g_loss=2.3928\n","[ep 2/2 | step 2800] d_loss=0.2891 | g_loss=2.6154\n","[ep 2/2 | step 2850] d_loss=0.3818 | g_loss=3.0064\n","[ep 2/2 | step 2900] d_loss=0.1630 | g_loss=2.0724\n","[ep 2/2 | step 2950] d_loss=0.2963 | g_loss=2.2530\n","[ep 2/2 | step 3000] d_loss=0.4316 | g_loss=1.9775\n","[ep 2/2 | step 3050] d_loss=0.1782 | g_loss=2.4504\n","[ep 2/2 | step 3100] d_loss=0.2657 | g_loss=2.3376\n","[ep 2/2 | step 3150] d_loss=0.2578 | g_loss=2.7009\n","[ep 2/2 | step 3200] d_loss=0.2484 | g_loss=2.2633\n","[ep 2/2 | step 3250] d_loss=0.4409 | g_loss=2.9729\n","[ep 2/2 | step 3300] d_loss=1.2927 | g_loss=3.8009\n","[ep 2/2 | step 3350] d_loss=0.4503 | g_loss=1.1615\n","[ep 2/2 | step 3400] d_loss=0.4958 | g_loss=1.8658\n","[ep 2/2 | step 3450] d_loss=0.5264 | g_loss=1.9532\n","[ep 2/2 | step 3500] d_loss=0.4256 | g_loss=2.2283\n","[ep 2/2 | step 3550] d_loss=0.3006 | g_loss=2.0578\n","[ep 2/2 | step 3600] d_loss=0.2749 | g_loss=2.5200\n","[ep 2/2 | step 3650] d_loss=0.2942 | g_loss=1.9040\n","[ep 2/2 | step 3700] d_loss=0.3060 | g_loss=2.3287\n","[ep 2/2 | step 3750] d_loss=0.4229 | g_loss=2.4501\n","[ep 2/2 | step 3800] d_loss=0.2776 | g_loss=2.9011\n","[ep 2/2 | step 3850] d_loss=0.1772 | g_loss=2.8431\n","[ep 2/2 | step 3900] d_loss=0.5153 | g_loss=1.9145\n","[ep 2/2 | step 3950] d_loss=0.4639 | g_loss=2.6511\n","[ep 2/2 | step 4000] d_loss=0.5335 | g_loss=2.0336\n","[ep 2/2 | step 4050] d_loss=0.4254 | g_loss=2.1156\n","[ep 2/2 | step 4100] d_loss=0.7318 | g_loss=3.0967\n","[ep 2/2 | step 4150] d_loss=1.0243 | g_loss=3.2849\n","[ep 2/2 | step 4200] d_loss=0.3566 | g_loss=2.5332\n","[ep 2/2 | step 4250] d_loss=0.4859 | g_loss=2.8340\n","[ep 2/2 | step 4300] d_loss=0.2835 | g_loss=1.9830\n","[ep 2/2 | step 4350] d_loss=0.4838 | g_loss=2.2799\n","[ep 2/2 | step 4400] d_loss=0.4017 | g_loss=1.6589\n","[ep 2/2 | step 4450] d_loss=0.4761 | g_loss=2.4101\n","[ep 2/2 | step 4500] d_loss=0.3437 | g_loss=1.6837\n","[ep 2/2 | step 4550] d_loss=0.4486 | g_loss=2.0103\n","[ep 2/2 | step 4600] d_loss=0.4817 | g_loss=2.1717\n","[ep 2/2 | step 4650] d_loss=0.2737 | g_loss=2.7760\n","[ep 2/2 | step 4700] d_loss=0.3467 | g_loss=2.5569\n","[ep 2/2 | step 4750] d_loss=0.6489 | g_loss=2.2989\n","[ep 2/2 | step 4800] d_loss=0.5271 | g_loss=1.8981\n","[ep 2/2 | step 4850] d_loss=0.5031 | g_loss=1.8752\n","[ep 2/2 | step 4900] d_loss=0.2775 | g_loss=2.3739\n","[ep 2/2 | step 4950] d_loss=0.5930 | g_loss=2.3161\n","[ep 2/2 | step 5000] d_loss=0.3762 | g_loss=3.5868\n","[ep 2/2 | step 5050] d_loss=0.2663 | g_loss=2.2865\n","[ep 2/2 | step 5100] d_loss=0.3259 | g_loss=2.6287\n","[ep 2/2 | step 5150] d_loss=0.2591 | g_loss=3.0963\n","[ep 2/2 | step 5200] d_loss=0.4689 | g_loss=3.1545\n","[ep 2/2 | step 5250] d_loss=0.5283 | g_loss=2.3062\n","[ep 2/2 | step 5300] d_loss=0.4496 | g_loss=2.3792\n","[ep 2/2 | step 5350] d_loss=0.2923 | g_loss=3.1192\n","[ep 2/2 | step 5400] d_loss=0.2708 | g_loss=2.8166\n","[ep 2/2 | step 5450] d_loss=0.4505 | g_loss=2.2477\n","[ep 2/2 | step 5500] d_loss=0.4638 | g_loss=1.8773\n","[ep 2/2 | step 5550] d_loss=0.1997 | g_loss=3.7876\n","[ep 2] MMD=0.0416\n"]}],"source":["import numpy as np\n","import sys\n","from importlib import reload\n","import torch\n","\n","# Assicurati di avere gi√† caricato in RAM X_train e S_train\n","# Se non li hai ancora caricati, fallo cos√¨:\n","# BASE = \"/kaggle/working/traffic-tts-cgan\"\n","# X_train = np.load(f\"{BASE}/data_norm/X_train_norm.npy\")\n","# S_train = np.load(f\"{BASE}/data_norm/S_train_norm.npy\")\n","\n","assert X_train.shape[1:] == (120,5), f\"Shape X_train errata: {X_train.shape}\"\n","assert S_train.shape[1] == 4, f\"Shape S_train errata: {S_train.shape}\"\n","\n","# Aggiungo src al path\n","sys.path.insert(0, \"/kaggle/working/traffic-tts-cgan/src\")\n","\n","# Importo il modulo train\n","import train as t\n","reload(t)\n","\n","# Lancio il training\n","G, D, cfg = t.train_gan(\n","    X_train=X_train,\n","    S_train=S_train,\n","    proj_dir=\"/kaggle/working/traffic-tts-cgan\",\n","    batch_size=64,   # riduci a 64 se va in OOM\n","    epochs=2,         # debug rapido: 2-3 epoche bastano\n","    lr=1e-4,\n","    latent_dim=128,\n","    d_model=128,\n","    depth=4,\n","    nhead=8,\n","    ff_dim=512,\n","    dropout=0.1,\n","    workers=2,\n","    use_amp=False,    # üîß disattiva AMP finch√© non risolvi i problemi con SDPA\n","    r1_every=8,\n","    r1_gamma=1.0,\n","    seed=42,\n",")\n"]},{"cell_type":"code","execution_count":20,"id":"67638c32","metadata":{"execution":{"iopub.execute_input":"2025-09-30T19:29:32.243199Z","iopub.status.busy":"2025-09-30T19:29:32.242284Z","iopub.status.idle":"2025-09-30T19:29:52.717172Z","shell.execute_reply":"2025-09-30T19:29:52.716404Z"},"papermill":{"duration":20.535615,"end_time":"2025-09-30T19:29:52.718588","exception":false,"start_time":"2025-09-30T19:29:32.182973","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["  adding: kaggle/working/ (stored 0%)\r\n","  adding: kaggle/working/traffic-tts-cgan/ (stored 0%)\r\n","  adding: kaggle/working/traffic-tts-cgan/src/ (stored 0%)\r\n","  adding: kaggle/working/traffic-tts-cgan/src/utils.py (deflated 60%)\r\n","  adding: kaggle/working/traffic-tts-cgan/src/dataset.py (deflated 55%)\r\n","  adding: kaggle/working/traffic-tts-cgan/src/__pycache__/ (stored 0%)\r\n","  adding: kaggle/working/traffic-tts-cgan/src/__pycache__/train.cpython-311.pyc (deflated 51%)\r\n","  adding: kaggle/working/traffic-tts-cgan/src/__pycache__/losses.cpython-311.pyc (deflated 45%)\r\n","  adding: kaggle/working/traffic-tts-cgan/src/__pycache__/utils.cpython-311.pyc (deflated 55%)\r\n","  adding: kaggle/working/traffic-tts-cgan/src/__pycache__/dataset.cpython-311.pyc (deflated 48%)\r\n","  adding: kaggle/working/traffic-tts-cgan/src/__pycache__/models.cpython-311.pyc (deflated 60%)\r\n","  adding: kaggle/working/traffic-tts-cgan/src/losses.py (deflated 52%)\r\n","  adding: kaggle/working/traffic-tts-cgan/src/models.py (deflated 71%)\r\n","  adding: kaggle/working/traffic-tts-cgan/src/train.py (deflated 65%)\r\n","  adding: kaggle/working/traffic-tts-cgan/setup_dirs.py (deflated 37%)\r\n","  adding: kaggle/working/traffic-tts-cgan/data_norm/ (stored 0%)\r\n","  adding: kaggle/working/traffic-tts-cgan/data_norm/X_train_norm.npy (deflated 47%)\r\n","  adding: kaggle/working/traffic-tts-cgan/data_norm/S_train_norm.npy (deflated 58%)\r\n","  adding: kaggle/working/traffic-tts-cgan/outputs/ (stored 0%)\r\n","  adding: kaggle/working/traffic-tts-cgan/outputs/samples/ (stored 0%)\r\n","  adding: kaggle/working/traffic-tts-cgan/outputs/checkpoints/ (stored 0%)\r\n","  adding: kaggle/working/traffic-tts-cgan/outputs/checkpoints/ckpt_ep002.pt (deflated 9%)\r\n","  adding: kaggle/working/__notebook__.ipynb (deflated 81%)\r\n"]}],"source":["!zip -r working_dir.zip /kaggle/working/\n"]},{"cell_type":"code","execution_count":null,"id":"2e791f95","metadata":{"papermill":{"duration":0.008904,"end_time":"2025-09-30T19:29:52.737445","exception":false,"start_time":"2025-09-30T19:29:52.728541","status":"completed"},"tags":[]},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":8105495,"sourceId":12817926,"sourceType":"datasetVersion"}],"dockerImageVersionId":31090,"isGpuEnabled":true,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"papermill":{"default_parameters":{},"duration":664.411149,"end_time":"2025-09-30T19:29:54.970877","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-09-30T19:18:50.559728","version":"2.6.0"}},"nbformat":4,"nbformat_minor":5}